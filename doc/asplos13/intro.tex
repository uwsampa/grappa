\section{Introduction} \label{sec:intro}

Computing on large graph datasets is both important and challenging.  Underlying many applications critical for national security, market analysis, and social computing are algorithms that process large graphs.  Three basic factors make these applications challenging for traditional computing systems: (1) the datasets are enormous -- far more than can fit within a single computing system's memory; (2) the computation to communication ratio is low -- applications spend most of their time fetching nodes and edges of the graph, and the computation performed on that data often takes a trivial amount of time by comparison; and (3) graph datasets have little to no locality, defying traditional mechanisms architects have designed, such as caches and prefetching, for improving memory system performance.

Traditionally, when organizations had to process large graphs they would turn to the Cray XMT~\cite{xmt} line of machines.  The XMT is well suited to the processing of large graphs: it has a large distributed shared memory, and instead of relying on caches to exploit locality, it relies on fine-grained multithreading to tolerate access latency.  Locality in the data access stream is not required, if sufficient threads exist to overlap computation with communication.  The XMT machines have two basic detractions, however: (1) they are not inexpensive because customers cannot exploit the economics of commodity hardware and software; and (2) applications designed to execute on commodity clusters cannot be automatically ported to the XMT with good performance.  Users of the XMT need to commit to its style and language of software development.

In this paper we describe Grappa, a software runtime system built for your typical high-performance compute cluster, that makes graph algorithms fast and scalable.  Grappa is inspired by the XMT hardware, but implements the key mechanisms of that design in software, and adds additional software components to tolerate the differences between a typical compute cluster and the more specialized XMT hardware.  A useful analogy is that Grappa is to graph processing, as Hadoop~\cite{hadoop} is to map-reduce.

By design, Grappa is built on as much freely available and commodity infrastructure as possible.  We use unmodified Linux for the operating system.  An off the shelf user-mode infiniband device driver stack~\cite{Melonox?} is used for network interfacing.  MPI~\cite{mpi} is used for process setup and tere down.  Finally, GASnet~\cite{gasnet} is used as the underlying mechanism for remote memory reads and writes and active message invocation.

To this commodity hardware and software mix Grappa adds three main software components: (1) a lightweight tasking layer that supports a context switch in as few as \checkme{40ns} and distributed load balancing; (2) a distributed shared memory layer that supports customary operations such as read and write as well as remote operations such as fetch-and-add~\cite{fetchandadd}; and (3) a message aggregation layer that mitigates the problem where commodity networks are designed to achieve peek bandwidth only on large packet sizes, yet graph algorithms tend to want to fetch only a handful of bytes at a time.  Each of these components will be described in more detail in Section~\ref{sec:grappa}.

Grappa achieves its design goal, which is to make graph algorithms execute quickly and scalably on commodity clusters.  Our yardstick for comparison is the XMT hardware itself.  Using the same number of processors (in our case cores on a single multicore processor), Grappa is in the same ballpark as the XMT: on some graphs, such as the \checkme{WTF} Grappa is \checkme{2X} faster, while on others, such as the \checkme{WTF2} Grappa is \checkme{2X} slower.  In Section~\ref{sec:results} we explore the factors that underpin this performance.  But most importantly, application performance \emph{scales} with Grappa.  For significantly less real world cost, users can \emph{add} more processors to a commodity cluster and easily outperform the XMT hardware on graph processing, while still saving significant dollars.

\TODO{Add roadmap here}

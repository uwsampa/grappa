\section{Implementation} \label{sec:implementation}

We now discuss implementation details for the major system components discussed in Section~\ref{sec:grappa}.

\subsection{Tasking}

\subsubsection{Tasks and workers}

Grappa tasks are 32-byte entities: a 64-bit function pointer plus
three 64-bit arguments. We use three arguments because tasks are
usually generated as part of a parallel loop decomposition, and thus
each task needs three kinds of data:
\begin{description}
\item[Function pointer] This 64-bit value indicates what routine
  should run. We depend on the fact that all processes in the system
  load the same binary so that function pointers are consistent across
  processes.
\item[Private argument] This 64-bit value is used for task-specific
  data, and is often a loop index.
\item[Shared argument] This 64-bit value is used for data shared
  between all tasks that are part of a loop, and is usually a global
  pointer to a struct. Each task uses its private argument to 
\item[Synchronization argument] This 64-bit value is used to determine
  when all tasks that are part of a loop have finished. It is usually
  a global pointer to a synchronization object allocated at the core
  that spawned the task.
\end{description}
While these are the most common uses of the three task arguments, they
are treated as arbitray 64-bit values in the runtime, and can be used
to store whatever the user wants.

Tasks are not allocated any execution resources until the scheduler
decides to run them; when this occurs, tasks are matched with {\em
  workers}. Each worker simply a collection of status bits and a
stack, allocated at a particular core. Workers 


\subsubsection{Context switching}

Context switching in Grappa is non-preemptive. Any Grappa routine that
does a potentially-long-latency operation calls a context-switch
routine that gives control of the core back to the scheduler. Users
may also explicity yield control to the scheduler.

As with other cooperative multithreading systems, we treat context
switches as function calls, saving and restoring only the callee-saved
state as specified in the x86-64 ABI \TODO{cite}. This involves saving
six general-purpose 64-bit registers and the stack pointer, as well as
the 16-bit x87 floating point control word and the SSE context/status
register. Thus, the minimum amount of state a cooperative context
switch routine must save according to the ABI is 62 bytes.

Since the compiler sees all calls to the context switch routine, we
can save even less state. Our context switch routine appears to the
compiler as inline assembly; we can declare all the registers we need
to save as ``clobbered'' by the inline assembly routine, and the
compiler will issue its own save and restore code. This allows the
compiler to avoid saving any registers that are not used, or are used
for temporary values that are not needed after the context switch. In
particular, only one of our applications does floating point
operations; all the other applications can safely ignore the x87 and
SSE2 registers as part of context switching.

\subsubsection{Scheduling}

Each core in the Grappa system has its own independent scheduler. Each
scheduler has three main tasks to perform.  First, it must ensure that
its communication resources are serviced reasonably often. Second, it
must ensure that if a running task was waiting on a long-latency
operation and that operation has completed, the task will be
rescheduled. Third, if there are tasks waiting to be run and spare
execution resources, the tasks must be matched with idle workers.

Each scheduler has three queues:
\begin{description}
\item{Ready worker queue} This is a FIFO queue of tasks that are
  matched with workers and are ready to execute.
\item{Private task queue} This is a FIFO queue of tasks that must run on this core.
\item{Public task queue} This is a LIFO queue of tasks that are
  waiting to be matched with workers. Tasks may be stolen from this
  queue by other cores in the system; this is described in the next section.
\end{description}

Whenever a task yields or suspends, the scheduler makes a decision
about what to do next. First, it determines if it is time to service
the communication resources should be serviced. This is done on a
periodic basis. Second, it determines if any workers with running
tasks are ready to execute; if so, one is scheduled. Finally, if there
are no workers ready to run, but there are tasks waiting to be matched
with workers, an idle worker is woken (or a new worker is spawned),
matched with a task, and scheduled.

The scheduler uses its core's timestamp counter to track time. The
timestamp counter is read once per scheduling decision. Timestamp
values are not shared between cores. We use timestamp values only to
ensure period execution of communication maintenance tasks; being
wrong will only change the rate of these events with a potential
performance cost, and no correctness violation. Nevertheless, we
assume Grappa will run on machines with modern timestamp counter
implementations that are monotonic and frequency-compensated.

\subsubsection{Work stealing}

\TODO{BrandonM or Jacob}

\subsection{Communication}


\subsection{Aggregation}

\subsection{Synchronization}

\subsection{Consistency}

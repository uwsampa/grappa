\section{Evaluation}
\label{sec:evaluation}

The goal of our evaluation is to show that the core pieces of the \Grappa
runtime system, namely our tasking system and the global memory/communication
layer work as expected and together are able to efficiently run irregular
applications. We evaluate \Grappa in three basic steps:

\begin{itemize}

\item We present results that show that \Grappa can
    support large amounts of concurrency, sufficient for remote memory
    access and aggregation. The communication layer is able to
    sustain a very high rate of global memory operations. We also show the performance of a
graph kernel that stresses communication and concurrency together.
\TODO{compare to key-value stores?}

\item We characterize system behavior, including
profiling where execution time goes, how aggregation affects message size and
rates, and \checkme{the relationship between aggregation and
    concurrency.}

\item Finally, we show how some more realistic irregular workloads on \Grappa
compare to the Cray XMT and hand-tuned MPI code.

\TODO{Grappa is well-suited to applications where there is
    abundant data parallelism but unpredictable or imbalanced data
    access. BSP is efficient where there is sufficient parallel slack.
    Although Grappa loses some asynchrony by relying heavily on
    aggregation, it still provides more flexibility for sections of the
    computation to proceed more quickly. }

\TODO{how much concurrency is needed on apps. Our basic plot of
    performance vs workers (with and without aggro?)}
\TODO{relationship between user-thread-visible latency and aggregate throughput.}
\TODO{characterization of aggregation message size vs nodes}
\TODO{show our scalability plots; if they don't scale, show
    specifically why. It is okay if its because aggregation stops
    working after a point if we can discuss future scalability.
    Perhaps reference ``MPI on millions of cores'' type work}

\end{itemize}

\subsection{Basic \Grappa Performance}
\label{eval:basic}

\paragraph{User-level context switching.}

Fast context switching is at the heart of \Grappa's
latency tolerance abilities. We assess context switch overheads using a simple
microbenchmark that runs a configurable number of workers on a single core, where each worker 
increments values in a large array. 

\begin{figure}[ht]
    \begin{center}
      \includegraphics[width=0.5\textwidth]{figs/context_switch_time.pdf}
    \end{center}
    \caption{Average context switch time with and without prefetching.}
    \label{fig:context-switch-exp}
\end{figure}

Figure~\ref{fig:context-switch-exp} shows the average context switch
time as the number of workers grow. At our standard operating point
($\approx$1K workers), context switch time is on the order of
50ns. As we add workers, the time increases slowly, but levels off:
we also ran with 500,000 workers (10~times what is shown in the
figure) and found that context switch time was around 75ns. In
comparison, for the same yield test using kernel-level Pthreads on a
single core, the switch time is 450ns for a few threads and 800ns for
1000--32000 threads.

If we calculate aggregate context switch \emph{rate\/} of all
cores in a node, we find that with prefetching, \Grappa context
switching is
limited \emph{not\/} by memory latency, as normally assumed, but rather memory bandwidth.
Specifically, we empirically found that 4~cache lines (1~for worker
struct and 3 for stack data) was sufficient to avoid cache misses in
the microbenchmark. Every context switch then requires 8~cache-line transfers. The off-chip
bandwidth of a single socket in our system is 270M cache lines per
second~\cite{porterfield:bw,Nelson:hotpar11}. This implies that, in the limit,
we can sustain at most 34M context switches per second per socket (a context-switch time of 29ns).
\TODO{based on this and GUPS, our message rate will be limited by
    context switching for small+single messages. One experiment is
    GUPs with context switching, where we vary number of reads/suspend}

In summary, our context switch engine is able to efficiently sustain very high
concurrency and, as we will show later, the amount of concurrency sustained is
sufficient for the latencies \Grappa needs to hide.

\paragraph{Global memory and communication.} We measure the performance of
\Grappa's global memory and communication layers using a faithful
implementation of the giga updates per second (GUPs) benchmark, which
measures cluster-wide random access bandwidth.  Read-modify-write
updates are dispatched at random to a large array. This benchmark
stresses the communication layer of \Grappa separately from the
scheduler, because only a single worker is used per system node.
Figure~\ref{fig:grappa-gups} shows that \Grappa is able to sustain
well over a billion updates per second with 64~nodes. Note also that
when aggregation is turned off, the update rate is nearly
flat. Clearly aggregation is instrumental for good communication
performance.

This compares very favorably to published results~\cite{gups} for other
high-end HPC systems. Though the actual computation done by GUPS is not 
useful, irregular, data-intensive applications typically must be able to
sustain a high rate of random accesses in order to, for example, visit and
mark vertices during a graph traversal. High random access rate in a
distributed setting has been a long-standing challenge in HPC.

\begin{figure}[ht]
    \begin{center}
      \includegraphics[width=0.5\textwidth]{figs/gups.pdf}
    \end{center}
    \caption{GUPS (giga updates per second) for \Grappa as the number of nodes grows with and without message aggregation.}
    \label{fig:grappa-gups}
\end{figure}

\TODO{go into more detail about what Grappa is doing when executing
    GUPs. Specifically note what the rate per core is, what the
    aggregation and deaggregation rates are. Show on the plot the
    message size distribution (some box plot)}

\paragraph{Putting it all together with Unbalanced Tree Search in memory
(UTS).} 
Figure~\ref{fig:grappa-uts} shows the overall performance of \Grappa running
UTS. This experiment demonstrates that \Grappa's context
switching and communication layers can be used together, while
balancing workload, to run an irregular application efficiently. 

Visiting vertices in the distributed tree requires mostly remote
accesses, and because each vertex in the tree must be visited before
it can be expanded, blocking remote reads are required. In this case,
we are forced to context switch to tolerate the remote access and
continue aggregating.

We look at two classes of trees, T1 and T3, from
the original benchmark. T1 trees are very shallow and wide (i.e., significant
parallel slack \TODO{cite Valiant and say more somewhere about BSP}), while T3 trees are very deep (i.e., little parallel slack).
When the access to each vertex is a random access, the critical path to search
T3 trees is very long, hence the low performance and scalability. On such
trees, we do not expect there to be sufficient concurrency for any system,
including \Grappa, to achieve high throughput -- at the 16-node data point,
the average active tasks per core over the search is 775 for T1 and
only 13 for T3.
On the other hand, \Grappa performs and scales very well for T1
trees.


\begin{figure}[ht]
    \begin{center}
      \includegraphics[width=0.5\textwidth]{figs/uts_scale.pdf}
    \end{center}
    \caption{Vertices per second in UTS on \Grappa as the number of nodes grows.}
    \label{fig:grappa-uts}
\end{figure}

\subsection{Comparing \Grappa to Other Systems}
\label{eval:mainperf}

In order to put \Grappa's performance into a general context, we compare it
with XMT running BFS, PageRank, IntSort, GUPS and UTS. Since XMT is a
different hardware platform, we also compare \Grappa with optimized MPI
versions of BFS and GUPS running on the same hardware. Finally, we also
compare it with UTS written for UPC. We run all experiments with 64 nodes and 16 cores per node.

% \begin{figure}[ht]
%     \begin{center}
%       \includegraphics[width=0.5\textwidth]{results/benchmarks.pdf}
%     \end{center}
%     \caption{Comparing \Grappa with XMT, hand-tuned MPI and UPC.}
%     \label{fig:grappa-comparisons}
% \end{figure}

\begin{table}[htb]
\begin{center}
\begin{tabular}{l|c|c|c|c}
         & \Grappa & XMT   & MPI  & UPC \\ \hline
GUPS     & 1       & 2.23  & 0.11 & -- \\ 
BFS      & 1       & 1.63  & 3.52 & -- \\ 
IntSort  & 1       & 3.59  & 5.36 & -- \\
UTS (T1) & 1       & 0.38  & --   & 0.09 \\ 
Pagerank & 1       & 4.35  & 4.87 & -- \\ 
\end{tabular}
\end{center}
\caption{Comparing \Grappa with XMT, optimized MPI and UPC. Numbers are presented as throughput on 64 nodes normalized to \Grappa.}
\label{tab:grappa-comparisons}
\end{table}

Table~\ref{tab:grappa-comparisons} shows the results. \Grappa is able
to provide performance approaching and sometimes exceeding that of the
other systems. This data shows that, while \Grappa is good at the
operations for which it was designed, there is a cost to providing
\Grappa's generality. In general, the benchmarks whose MPI
implementations are faster than \Grappa include a implementation of a
subset of \Grappa's functionality specialized for their particular
problem. We now discuss each benchmark in more detail.

\paragraph{UTS.}
It is perhaps not surprising that the XMT is faster than
\Grappa on many of the benchmarks; after all, the XMT is custom
hardware optimized for irregular applications. The XMT can
context-switch every cycle, while \Grappa takes $~$50 ns. The XMT can
complete 100 million random-access remote reads per second per node in
hardware, while \Grappa must spend many instructions managing and
aggregating each of these reads in software.

What is more surprising is that Grappa is able to exceed the XMT's
performance on UTS. This is a demonstration of the inflexibility of
custom hardware. Recall that the UTS benchmark searches an unbalanced
tree and spawns a data-dependent number of child tasks at each
vertex. The XMT's spawn/join semantics, whose implementation is spread
across the hardware, OS, and runtime, require a task visiting a vertex
to block until all its child tasks have completed, even though the
benchmark does not require those tasks to have completed until the end
of the tree search. Furthermore, each new task is immediately made
available to all other processors in the system, even though it is
likely that processor that spawned a task will end up executing it.

Since \Grappa's tasks are implemented entirely in software, it is easy
to support arbitrary synchronization semantics. \Grappa allows both
XMT-like per-vertex task joins as well as whole-problem joins that are
a better fit for UTS. Furthermore, \Grappa's work-stealing distributed
task queue and recursive loop decomposition encourage locality in task
execution, so that the system is optimized for the common case of a
processor executing a task it spawned.

The UPC UTS implementation includes an implementation of work-stealing
but has limited ability to overlap communication with
computation. Furthermore, it must execute heavyweight synchronization
operations when stealing. \Grappa benefits from its lightweight
context switching and support for fine-grained synchronization.

\paragraph{BFS.}
The Grappa and MPI BFS implementations are quite similar. They both
use the same graph representation, and they both depend on aggregation
for performance. The difference is that the BFS' aggregation is
integrated with the traversal code and specialized for the problem:
since the only messages required are edge traversals, the aggregation
buffers store only pairs of 8-byte vertex IDs.  In contrast, \Grappa
pays execution and space overhead in order to support aggregation of
arbitrary closures; the messages \Grappa aggregates include the two
8-byte vertex IDs along with 8 bytes of deserialization information as
well as 8 bytes of synchronization information. Furthermore, the MPI
implementation writes the edge information directly into the
aggregation buffer while \Grappa executes additional code to serialize
and deserialize the messages. \TODO{Include message counts, size, and
  rates; code size too?}.

\paragraph{GUPS.}
The MPI GUPS implementation includes an implementation of aggregation,
but it is not optimized to work when the aggregated data exceeds
cache, and it has limited support for concurrent communication with
multiple destinations. \Grappa benefits from being optimized for both
of these cases.

\paragraph{Pagerank.}
The MPI Pagerank implementation is built on top of the
highly-optimized sparse matrix support in the Trilinos~\cite{trilinos}
library. In contrast, the \Grappa implementation is a straightforward nested
loop.

\paragraph{IntSort.}
Both MPI and \Grappa IntSort implement a bucket sort. For \Grappa,
distributing keys into buckets accounts for the bulk of the execution
time; \Grappa does this using asynchronous delegate operations to
write the keys directly to their final destination. The MPI
implementation, on the other hand, first does a local sort of the keys
on each core, and then uses an \texttt{MPI\_Alltoallv()} collective
operation to move all the keys to their destination nodes in
bulk. This is essentially specialized aggregation combined with
collective communication. When we measure the time spent in this
region of both benchmarks, we find that the the sort and
\texttt{MPI\_Alltoallv()} are $~5\times$ faster than the \Grappa
version using generic aggregation and point-to-point communication. An
interesting future direction would be to extend \Grappa to support
aggregation via collective operations.


\paragraph{Summary.}

Overall, \Grappa provides a general programming model at a moderate
performance cost. While \Grappa's core functionality performs well,
applications can specialize similar functionality for their problems
and obtain better performance than \Grappa on the same hardware. This
is, however, not the end of the story for \Grappa's performance;
\Grappa is a young library and, as discussed in the next section, is
limited by its implementation rather than the hardware on which it
runs. We believe there are opportunities for optimization that will
improve its performance.

\subsection{Characterization}

\begin{table*}[htb]
\begin{center}
\begin{tabular}{l|c|c|c|c|c}
% remember: bfs time is mean_time * nbfs
                               &   GUPS            &   BFS   & IntSort & UTS & Pagerank \\ \hline
Application message rate/core  & 984K/s            &  983K   &           \\
%Application message bytes     & 31.8 $\pm$ 1.2    & \\
Avg. Application message bytes & 31.8              & 33.9    &       \\
Network bandwidth per node     & 478MB/s           & 511MB/s &          \\
%Network message bytes         & 23.2K $\pm$ 12.4K & \\ \hline
Avg. Network message bytes     & 23.2K             & 4.3K    &     \\ \hline
Avg. active tasks/core         & 0.9               & 58.2    &    \\
Max. active tasks/core         & 1                 & 128     &     \\
Avg. ready queue length/core   & 2.3               & 6.1     &      \\
Avg. Context switch rate/core & 34.2K/s           & 539K/s  &       \\ 
Steal count                    & 0                 & 0       &       \\
\end{tabular}
\end{center}
\caption{Internal runtime metrics, for 64-node, 16-core-per-node benchmark runs \TODO{Finish} }
\label{tab:grappa-metrics}
\end{table*}

\paragraph{Runtime metrics}
Table~\ref{tab:grappa-metrics} show a number of internal runtime
metrics collected while executing the benchmarks from the previous
section. These are per-core averages computed over all 1024 cores of
the 64-node, 16-core-per-node jobs.

The first group of four metrics relate to the communication
layer. Application messages refer to those issued by the user code;
network message refer to the aggregated packes sent over the wire. The
data show that most application messages are only a handful of bytes,
but our aggregator is able to turn them into packets of many kilobytes.

The next group of five metrics relate to the scheduler. We show the
average and maximum number of concurrently-executing tasks, along with
the average length of the ready queue and the average context switch
rate.  The last line shows the number of time a core stole work from
another core. Only UTS depends on work-stealing for performance; the
other applications exploit locality by binding tasks to specific cores
Nevertheless, even in UTS, which depends on work-stealing for
performance, steals are an infrequent occurance and account for a
small fraction of the execution time.



\begin{figure}[ht]
    \begin{center}
      \includegraphics[width=0.5\textwidth]{results/plot_concurrency.pdf}
    \end{center}
    \caption{Throughput, request latency, and idleness as number of concurrent workers is varied}
    \label{fig:grappa-concurrency}
\end{figure}

\paragraph{How much concurrency does \Grappa require? How much latency does it add?}
Figure~\ref{fig:grappa-concurrency} shows 
UTS blocks at ea
\todo{FINISH}

\paragraph{Does \Grappa scale?}


\todo{FINISH}
Our current 


\paragraph{What limits \Grappa's performance?}
The most common operation in \Grappa is sending a message. Three key
operations occur in a message's lifetime: creating and enqueuing a
message, serializing a message in the aggregator, and deserializing a
message at the destination. We benchmarked each of these steps
individually to find the bottleneck.

Minimum-sized messages can be created and enqueued at a rate of 16M/s,
serialized into an aggregation buffer at 32M/s, and deserialized from
an aggregation buffer at 210M/s.  Together, these rates limit us to
$~$10M/s per core in the best case. In a blocking application, the
context switch costs (50ns, or 20M/s) bring this maximum down to
7M/s. In practice, \Grappa does not achieve this maximum; the current
aggregator design communicates inefficiently between cores within a
node, limiting our message rate to to $~$1M/s per core with messages
of common sizes. Future work will reduce this cost.












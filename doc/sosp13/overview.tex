\section{\Grappa Overview}

% \TODO{Whats missing before diving into the system
%     is why we think we can build a system with these
%     techniques and it will work well--myers}

\begin{figure}[t]
\begin{center}
  \includegraphics[width=0.95\columnwidth]{figs/system-overview}
\begin{minipage}{0.95\columnwidth}
  \caption{\label{fig:grappa} \Grappa system overview}
\end{minipage}
\vspace{-3ex}
\end{center}
\end{figure}


\Grappa (Figure~\ref{fig:grappa}) has three main software components:
\begin{description}

\item [Tasking system.] The tasking system supports lightweight multithreading
to tolerate communication latency and global distributed work-stealing (i.e.,
tasks can be stolen from any node in the system), which provides automated
load balancing. The scheduler oversubscribes to have more worker threads than
required for latency tolerance. By having at least several threads ready to
run at all times, the scheduler can prefetch a context data into cache to
lower the likelihood of costly main memory accesses during a context switch. 

\item[Distributed shared memory.] The DSM system provides
fine-grain access to data anywhere in the system. It supports synchronization
operations on global data, explicit local caching of any memory in the system,
and support for operations on remote data.
The DSM system design relies on the lightweight tasking system and
communication layer in order to offer high aggregate random
access bandwidth for accessing remote data.

\item[Communication layer.] Modern commodity networks
support high bandwidth only for large messages. Since irregular applications
tend to need frequent communication of small requests, the main goal of our
communication layer is to aggregate small messages into large ones to better
exploit what the network can offer. It is largely invisible to the application
programmer.

% software developer but helps to improve network performance when applications read and write only small pieces of data.

\end{description}

% \paragraph{Exploiting Latency Tolerance} As we will show later, \Grappa can tolerate latencies way beyond that of the network. Therefore, \Grappa can afford to \emph{trade latency for throughput\/}: by {\em increasing\/} latency in key components of the system we are able to increase our aggregate random access bandwidth (by delaying and aggregating messages), our synchronization bandwidth (by delegating operations to remote nodes), and our ability to improve load imbalance (work stealing increases latency).

% \TODO{check to see we actually explain these three somewhere.  Ie, that aggregating increases throughput and latency, that delegating synchronization increases the rate and the latency at which we can eg atomically increment, and that stealing work increases the latency of some tasks (eg when their data is largely at the originating node) but provides greater throughput overall.}

In the next three sections we describe both \Grappa's main components and how they are implemented.


\section{Conclusion}

Irregular computations are both important and challenging to execute quickly.
Scaling these applications easily to commodity hardware has been a historical
challenge. \Grappa is a runtime framework that simplifies this task for
software developers and compiler writers. This paper describes the \Grappa
framework and its three main components: a task library, a distributed shared
memory system, and a network aggregator to make commodity networks efficient
with small message sizes. \Grappa's key aspect is extreme latency tolerance,
which not only hides network latency but also enables the system to spend time
on sophisticated work stealing and network optimizations, trading latency for
even more throughput.

Our evaluation of \Grappa reveals that the core components, scheduling and communication, achieve their design goals.  Thousands of workers can be efficiently context switched on a multicore processor, up to the DRAM bandwidth.  Aggregating messages enables \Grappa to achieve over 1.0 GUPS on 64 nodes.  We also explored four other algorithms: unbalanced tree search, breadth first search, PageRank, and integer sort, comparing performance of these algorithms on \Grappa, the Cray XMT, and against hand-optimized MPI implementations.  As would be expected, when the MPI implementation exploits in the application, many of the same techniques \Grappa provides in the runtime, such as aggregating requests, yet without the overhead of tasking, the MPI implementation excels.  This comes with enormous implementation complexity burdened on the application developer, however, and significant tuning has yet to be done on the \Grappa runtime system.  Compared to the Cray XMT \Grappa is between 2X faster and 4X slower.  Yet when cost-performance is considered, mass-market x86 cluster hardware makes \Grappa a highly attractive option.

\relax 
\citation{tera:mta1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{OFED}
\citation{gasnet}
\citation{fetchandadd}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Description of the Current Grappa System}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Tasks}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Grappa API: scheduling\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:scheduling}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Expressing parallelism}{3}}
\citation{cilkforimplementation}
\citation{intel_tbb}
\citation{MAMA,flatcombining}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  Grappa API: expressing parallelism\relax }}{4}}
\newlabel{fig:expressing-parallelism}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Memory}{4}}
\@writefile{toc}{\contentsline {paragraph}{Global memory addressing}{4}}
\citation{Chen:2005}
\citation{FortranD:1992}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Grappa API: accessing memory\relax }}{5}}
\newlabel{fig:accessing-memory}{{3}{5}}
\@writefile{toc}{\contentsline {paragraph}{Global memory access}{5}}
\citation{Nelson:hotpar11}
\citation{delegated:oopsla11}
\citation{vonEicken92}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Grappa memory structure\relax }}{6}}
\newlabel{fig:memory-structure}{{4}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Communication}{6}}
\newlabel{sec:communication}{{3.4}{6}}
\citation{infinibandbandwidth}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  \textbf  {Delegation and cache example:} In step 1, a core allocates an array in the global heap. It then spawns two tasks on remote cores to increment elements of the array. The first task increments two elements of the array using cache operations. In step 2, the task is invoked. A cache request is issued for two adjacent integers starting at the second element of the array. Since these element are stored in the memories of two different cores, this requires the sending of two messages in step 3. The task is suspended until both responses arrive in step 4. The data carried in these responses is stored in the local buffer. The elements are then increment in the buffer. Then in step 5, the modified data is sent back to the home node. Acknoledgements are returned in step 6 so the task knows when the writes are complete. The second task increments an element of the array with a delegate operation. In step 7, the task is invoked. A delegate request is sent to the home core of the array element with the increment value. The task suspends until the response is received. In step 8, the increment is executed on the remote core. A response is returned in step 9 with the previous value of the array element. \relax }}{7}}
\newlabel{fig:delegate-cache}{{5}{7}}
\citation{gasnet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Performance}{8}}
\@writefile{toc}{\contentsline {paragraph}{Unbalanced tree search}{8}}
\@writefile{toc}{\contentsline {paragraph}{BFS}{8}}
\@writefile{toc}{\contentsline {paragraph}{Centrality}{8}}
\bibstyle{abbrv}
\bibdata{proposal}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Performance of in-memory unbalanced tree search.\relax }}{1}}
\newlabel{fig:uts_compare}{{6}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  BFS performance\relax }}{2}}
\newlabel{fig:bfs-performance}{{7}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  Centrality performance\relax }}{3}}
\newlabel{fig:centrality-performance}{{8}{3}}

\documentclass{acm_proc_article-sp}
\begin{document}

\title{Latency-tolerant runtimes for large graph computations}

\numberofauthors{7}
\author{
(authors)
}

\maketitle
\begin{abstract}

  Large irregular applications such as sparse graph problems often
  perform badly on commodity clusters. These application often make
  many nonsequential accesses to global data structures with low
  degrees of locality, which interact badly with commodity processors'
  memory systems, which are optimized for local, sequential memory
  accesses.

  Custom hardware optimized for these irregular applications has been
  built: it exhibits excellent performance and energy efficiency for
  these applications, but performs badly on standard sequential
  workloads.

  We believe we can have the best of both worlds. We argue that modern
  commodity processors have many of the features necessary to give
  good performance on irregular problems, and that a latency-tolerant
  runtime designed to exploit these features can enable speedup for
  irregular applications. For the areas where commodity hardware is
  lacking, we suggest an approach for adding a small amount of
  additional hardware to make up the difference.

  In this paper, we describe the key features of such a model and
  runtime system. We show results from simple benchmarks run on a
  preliminary implementation of a latency-tolerant runtime that show
  this approach has promise.

\end{abstract}

\section{Introduction}

sparse graph problems important

Important 
Social networks
Facebook: 500M active users, 130 friends each on average. for
computing friend suggestions, 40-node cluster, 72GB/node, run every 2
days.






Most commodity processors sold today have multiple cores, and their 


perform badly on commodity processors, since most accesses are misses

context-swtiching for latency tolerance has been successful with MTA, but single thread performance sucks

we want latency tolerance on commodity processors for best of both worlds

could just wait for wider multicores, but if context switching works, we can get enough concurrency on fewer cores and shut off the rest.

\section{Programming model for graph problems}

many many threads

prefetch and switch on 

full/empty bits 

\subsection{Opportunities}

characteristics:



little FP use ==> don't worry about FP registers

would like enough concurrency to keep pipeline filled, but commodity CPUs don't have enough external bandwidth. So, get enough to saturate bandwidth.



\section{Approach}

Describe general approach.

\subsection{Low-latency context switch}

switch only stack pointer and program counter; depend on compiler to save/restore anything else. in general case, hopefully this will be fast.

\subsection{Memory concurrency}

Commodity procs don't provide enough. use software? FPGA?

\subsection{Synchronization}

use existing atomic instructions? Use FPGA listening snoops on QPI?


parition remote memory on each node; have one thread access each
partition, making sync easier

\section{Current Implementation and Results}

current: just context switch on single node


linked lists:

there is some room for memory concurrency

thread contexts don't take up too much space in cache

sparse matmul:

speedup?






\section{Related work}


hardware:

XMT/MTA

cyclops

niagra

software:

qthreads

cilk? tbb?



\section{Conclusion}

\end{document}
